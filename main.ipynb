{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3deba11-c34b-43c0-af00-a1f3076febe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import  tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "adadafef-ee74-4365-ac9c-e100364e74f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data set path\n",
    "file_path = \"flood.csv\"\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46df501a-f65a-441c-8b2e-3000e5e2d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "X = df.drop(columns=[\"FloodProbability\"])\n",
    "y = df[\"FloodProbability\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2417839-8070-4f12-9866-b88c4495924e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4de5d545-08e4-4f40-abe8-1df3dd8d65dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "743e9f07-0e3c-4903-bdd1-2573ee524cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network model\n",
    "def build_model():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        keras.layers.Dense(32, activation='relu'),\n",
    "        keras.layers.Dense(16, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='linear')  # Regression output\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca5ddf9a-834e-4aee-a325-47b9088bdc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mohan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - loss: 0.0141 - mae: 0.0771 - val_loss: 2.9142e-04 - val_mae: 0.0132\n",
      "Epoch 2/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0409e-04 - mae: 0.0110 - val_loss: 7.6411e-05 - val_mae: 0.0067\n",
      "Epoch 3/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 6.6763e-05 - mae: 0.0063 - val_loss: 3.8487e-05 - val_mae: 0.0046\n",
      "Epoch 4/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3.2151e-05 - mae: 0.0043 - val_loss: 2.2898e-05 - val_mae: 0.0037\n",
      "Epoch 5/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8961e-05 - mae: 0.0034 - val_loss: 1.5405e-05 - val_mae: 0.0030\n",
      "Epoch 6/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.2157e-05 - mae: 0.0027 - val_loss: 7.4209e-06 - val_mae: 0.0021\n",
      "Epoch 7/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 6.5971e-06 - mae: 0.0020 - val_loss: 2.3560e-06 - val_mae: 0.0011\n",
      "Epoch 8/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.3417e-06 - mae: 0.0014 - val_loss: 1.7528e-06 - val_mae: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.3019e-06 - mae: 0.0011 - val_loss: 4.7161e-07 - val_mae: 5.0711e-04\n",
      "Epoch 10/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.0788e-06 - mae: 7.8606e-04 - val_loss: 8.9202e-06 - val_mae: 0.0024\n",
      "Epoch 11/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0056e-06 - mae: 8.7616e-04 - val_loss: 1.1544e-06 - val_mae: 8.8684e-04\n",
      "Epoch 12/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 9.8980e-07 - mae: 7.3708e-04 - val_loss: 1.4705e-06 - val_mae: 0.0011\n",
      "Epoch 13/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 9.5131e-07 - mae: 6.9434e-04 - val_loss: 3.6923e-07 - val_mae: 4.0584e-04\n",
      "Epoch 14/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 6.3510e-07 - mae: 5.7727e-04 - val_loss: 7.3777e-07 - val_mae: 7.4609e-04\n",
      "Epoch 15/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.1368e-06 - mae: 7.1502e-04 - val_loss: 1.7746e-07 - val_mae: 3.2070e-04\n",
      "Epoch 16/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.4845e-07 - mae: 3.9298e-04 - val_loss: 6.8177e-08 - val_mae: 2.0330e-04\n",
      "Epoch 17/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.1767e-07 - mae: 3.0612e-04 - val_loss: 2.0181e-07 - val_mae: 3.4859e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.6760e-07 - mae: 4.2114e-04 - val_loss: 1.7676e-06 - val_mae: 0.0011\n",
      "Epoch 19/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 7.3487e-07 - mae: 5.9147e-04 - val_loss: 4.5852e-07 - val_mae: 4.9838e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.5138e-07 - mae: 2.6692e-04 - val_loss: 4.0664e-07 - val_mae: 5.1479e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3.1329e-07 - mae: 3.7192e-04 - val_loss: 4.3931e-08 - val_mae: 1.4650e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.5468e-07 - mae: 2.2877e-04 - val_loss: 1.3030e-08 - val_mae: 8.4500e-05\n",
      "Epoch 23/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.7450e-07 - mae: 2.6699e-04 - val_loss: 7.5269e-07 - val_mae: 6.5093e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.6356e-07 - mae: 3.7242e-04 - val_loss: 8.6270e-08 - val_mae: 2.4226e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.4687e-07 - mae: 3.8242e-04 - val_loss: 2.3208e-08 - val_mae: 1.2140e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.7955e-07 - mae: 2.0890e-04 - val_loss: 6.4192e-08 - val_mae: 1.8157e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.6410e-08 - mae: 1.3267e-04 - val_loss: 3.5701e-08 - val_mae: 1.6196e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.3608e-07 - mae: 2.2465e-04 - val_loss: 1.4295e-06 - val_mae: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 5.3164e-07 - mae: 4.7286e-04 - val_loss: 3.6288e-07 - val_mae: 4.6578e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.3058e-07 - mae: 3.0687e-04 - val_loss: 4.9423e-08 - val_mae: 1.7492e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8435e-07 - mae: 2.6143e-04 - val_loss: 1.2582e-08 - val_mae: 8.5232e-05\n",
      "Epoch 32/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.0994e-07 - mae: 3.2183e-04 - val_loss: 2.2071e-08 - val_mae: 1.3474e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 1.0008e-07 - mae: 1.7501e-04 - val_loss: 5.2507e-08 - val_mae: 1.9790e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.7160e-07 - mae: 2.8304e-04 - val_loss: 2.6330e-07 - val_mae: 4.2383e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.9106e-07 - mae: 4.3040e-04 - val_loss: 1.0560e-07 - val_mae: 2.6313e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.7411e-07 - mae: 3.6597e-04 - val_loss: 8.7412e-08 - val_mae: 2.3544e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.8586e-07 - mae: 3.9510e-04 - val_loss: 7.9883e-07 - val_mae: 6.6685e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3.5110e-07 - mae: 4.0504e-04 - val_loss: 4.7870e-07 - val_mae: 5.5509e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.3693e-07 - mae: 3.1877e-04 - val_loss: 2.6298e-07 - val_mae: 4.1761e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0471e-07 - mae: 3.0669e-04 - val_loss: 1.9895e-07 - val_mae: 3.6600e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.7871e-07 - mae: 3.7487e-04 - val_loss: 1.2368e-07 - val_mae: 2.6619e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 2.0745e-07 - mae: 2.7349e-04 - val_loss: 1.7604e-08 - val_mae: 1.0748e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.3480e-07 - mae: 2.3037e-04 - val_loss: 1.2944e-07 - val_mae: 2.9098e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.5125e-07 - mae: 2.8154e-04 - val_loss: 5.9146e-07 - val_mae: 6.4816e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.1143e-07 - mae: 3.2156e-04 - val_loss: 1.0010e-08 - val_mae: 7.9337e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.3084e-07 - mae: 1.7262e-04 - val_loss: 1.7395e-08 - val_mae: 1.0434e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 3.9119e-07 - mae: 3.3592e-04 - val_loss: 1.3990e-06 - val_mae: 9.8870e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.7526e-07 - mae: 2.6178e-04 - val_loss: 5.4293e-07 - val_mae: 6.2240e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.4718e-07 - mae: 3.7194e-04 - val_loss: 2.3326e-08 - val_mae: 1.2260e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.2832e-07 - mae: 2.0709e-04 - val_loss: 2.1440e-07 - val_mae: 4.1442e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.1781e-07 - mae: 3.8849e-04 - val_loss: 1.8816e-09 - val_mae: 3.3352e-05\n",
      "Epoch 52/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 7.9251e-08 - mae: 1.4048e-04 - val_loss: 4.1917e-09 - val_mae: 5.0490e-05\n",
      "Epoch 53/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.2548e-07 - mae: 1.8434e-04 - val_loss: 4.0621e-09 - val_mae: 3.3359e-05\n",
      "Epoch 54/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.2312e-07 - mae: 1.9109e-04 - val_loss: 3.2307e-09 - val_mae: 4.5264e-05\n",
      "Epoch 55/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 7.4928e-08 - mae: 1.5464e-04 - val_loss: 4.3307e-08 - val_mae: 1.6744e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 6.2242e-08 - mae: 1.7153e-04 - val_loss: 5.5832e-08 - val_mae: 1.9917e-04\n",
      "Epoch 57/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.1781e-07 - mae: 2.0818e-04 - val_loss: 9.4134e-07 - val_mae: 8.9471e-04\n",
      "Epoch 58/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0648e-07 - mae: 2.9325e-04 - val_loss: 6.8678e-09 - val_mae: 5.8116e-05\n",
      "Epoch 59/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.4649e-07 - mae: 2.5963e-04 - val_loss: 2.3672e-07 - val_mae: 4.2840e-04\n",
      "Epoch 60/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.1902e-07 - mae: 2.4035e-04 - val_loss: 2.7217e-08 - val_mae: 1.2582e-04\n",
      "Epoch 61/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.6729e-07 - mae: 2.4949e-04 - val_loss: 2.0359e-07 - val_mae: 3.4403e-04\n",
      "Epoch 62/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.8974e-07 - mae: 3.0300e-04 - val_loss: 1.4622e-08 - val_mae: 9.9910e-05\n",
      "Epoch 63/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.1177e-07 - mae: 3.0021e-04 - val_loss: 1.9704e-07 - val_mae: 3.5961e-04\n",
      "Epoch 64/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.6139e-07 - mae: 2.3365e-04 - val_loss: 3.1587e-07 - val_mae: 4.5709e-04\n",
      "Epoch 65/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.2585e-07 - mae: 3.1705e-04 - val_loss: 3.6173e-08 - val_mae: 1.4046e-04\n",
      "Epoch 66/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.2122e-07 - mae: 2.3610e-04 - val_loss: 1.5359e-07 - val_mae: 3.0202e-04\n",
      "Epoch 67/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 8.5733e-08 - mae: 1.7254e-04 - val_loss: 1.6378e-08 - val_mae: 1.0060e-04\n",
      "Epoch 68/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.5407e-07 - mae: 1.8008e-04 - val_loss: 3.2338e-09 - val_mae: 4.4996e-05\n",
      "Epoch 69/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.2427e-07 - mae: 1.7862e-04 - val_loss: 1.0944e-07 - val_mae: 2.5773e-04\n",
      "Epoch 70/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.4929e-07 - mae: 2.7292e-04 - val_loss: 4.7802e-09 - val_mae: 6.3530e-05\n",
      "Epoch 71/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 2.5250e-07 - mae: 2.5975e-04 - val_loss: 2.1834e-07 - val_mae: 3.6822e-04\n",
      "Epoch 72/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.5108e-07 - mae: 2.4309e-04 - val_loss: 9.7426e-08 - val_mae: 2.4396e-04\n",
      "Epoch 73/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.5470e-07 - mae: 2.8730e-04 - val_loss: 1.4280e-08 - val_mae: 9.3449e-05\n",
      "Epoch 74/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.5083e-07 - mae: 3.4813e-04 - val_loss: 5.2173e-08 - val_mae: 1.7961e-04\n",
      "Epoch 75/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.5097e-07 - mae: 2.3606e-04 - val_loss: 1.6272e-07 - val_mae: 3.7303e-04\n",
      "Epoch 76/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.7279e-07 - mae: 2.8805e-04 - val_loss: 1.7755e-07 - val_mae: 3.6598e-04\n",
      "Epoch 77/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.3687e-07 - mae: 2.5565e-04 - val_loss: 3.2403e-08 - val_mae: 1.4445e-04\n",
      "Epoch 78/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.9660e-07 - mae: 2.7894e-04 - val_loss: 3.3174e-08 - val_mae: 1.3325e-04\n",
      "Epoch 79/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.0300e-07 - mae: 2.2693e-04 - val_loss: 7.5640e-07 - val_mae: 7.0593e-04\n",
      "Epoch 80/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 1.1705e-07 - mae: 2.4290e-04 - val_loss: 1.9620e-07 - val_mae: 3.5394e-04\n",
      "Epoch 81/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.3421e-07 - mae: 2.5982e-04 - val_loss: 5.8606e-09 - val_mae: 6.1904e-05\n",
      "Epoch 82/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 9.5963e-08 - mae: 1.6388e-04 - val_loss: 5.7117e-09 - val_mae: 6.4867e-05\n",
      "Epoch 83/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.1008e-07 - mae: 2.3706e-04 - val_loss: 7.0694e-08 - val_mae: 2.1133e-04\n",
      "Epoch 84/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.0611e-07 - mae: 2.7916e-04 - val_loss: 2.3599e-08 - val_mae: 1.2179e-04\n",
      "Epoch 85/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - loss: 8.0048e-08 - mae: 1.8207e-04 - val_loss: 2.3326e-08 - val_mae: 1.2588e-04\n",
      "Epoch 86/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.7307e-08 - mae: 1.1189e-04 - val_loss: 5.6575e-10 - val_mae: 1.8415e-05\n",
      "Epoch 87/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.0951e-07 - mae: 1.6460e-04 - val_loss: 2.9634e-09 - val_mae: 4.2872e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.5347e-07 - mae: 2.3346e-04 - val_loss: 6.4145e-08 - val_mae: 1.9918e-04\n",
      "Epoch 89/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.9892e-08 - mae: 8.9323e-05 - val_loss: 1.0657e-09 - val_mae: 2.8656e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.2694e-07 - mae: 1.9773e-04 - val_loss: 7.1993e-08 - val_mae: 1.9249e-04\n",
      "Epoch 91/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.9862e-07 - mae: 2.7558e-04 - val_loss: 4.2260e-09 - val_mae: 2.7141e-05\n",
      "Epoch 92/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.0644e-07 - mae: 1.5679e-04 - val_loss: 8.5882e-10 - val_mae: 2.3213e-05\n",
      "Epoch 93/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 9.3157e-08 - mae: 1.6554e-04 - val_loss: 1.9965e-06 - val_mae: 0.0012\n",
      "Epoch 94/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.8579e-07 - mae: 2.4827e-04 - val_loss: 2.4908e-08 - val_mae: 1.1668e-04\n",
      "Epoch 95/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 3.4573e-08 - mae: 8.9694e-05 - val_loss: 9.9868e-10 - val_mae: 2.1859e-05\n",
      "Epoch 96/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 2.9199e-08 - mae: 8.9410e-05 - val_loss: 4.3259e-08 - val_mae: 1.5349e-04\n",
      "Epoch 97/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.5605e-07 - mae: 2.8440e-04 - val_loss: 1.0305e-08 - val_mae: 8.2007e-05\n",
      "Epoch 98/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 4.1001e-08 - mae: 1.1101e-04 - val_loss: 4.3426e-09 - val_mae: 4.7969e-05\n",
      "Epoch 99/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.6104e-07 - mae: 2.3758e-04 - val_loss: 1.1328e-07 - val_mae: 2.8739e-04\n",
      "Epoch 100/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - loss: 1.5896e-07 - mae: 2.8908e-04 - val_loss: 3.6104e-09 - val_mae: 5.1646e-05\n"
     ]
    }
   ],
   "source": [
    "# Build and train the model\n",
    "model = build_model()\n",
    "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba092ca0-3ff8-4573-81c1-eb99a6b30163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 3.6039e-09 - mae: 5.1343e-05\n",
      "Test MAE: 0.0001\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e44d734-606f-4abe-9bfe-d74407489c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "R² Score: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate R² Score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R² Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f1f48cf-3ab3-4f30-b51e-c14067f48cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the trained model\n",
    "model.save(\"model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cc3f11c-4743-49f3-b34c-38c4d467c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.42.2)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.5.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.1.8)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.0.0)\n",
      "Requirement already satisfied: packaging<25,>=20 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (24.1)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.2.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (10.4.0)\n",
      "Requirement already satisfied: protobuf<6,>=3.20 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (5.29.3)\n",
      "Requirement already satisfied: pyarrow>=7.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (19.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (2.32.3)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (8.5.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (4.12.2)\n",
      "Requirement already satisfied: watchdog<7,>=2.1.5 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (3.1.44)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from streamlit) (6.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (4.22.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from altair<6,>=4.0->streamlit) (1.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2024.6.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mohan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install streamlit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ad6c52-7444-4e64-83d7-6bbfc89a8dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555045c1-944d-4e80-bab7-cc29a8f89a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
